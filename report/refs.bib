
@INPROCEEDINGS{8999039,
  author={Soares Araujo, Carlos Vicente and Pinheiro de Cristo, Marco Antônio and Giusti, Rafael},
  booktitle={2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)}, 
  title={Predicting Music Popularity Using Music Charts}, 
  year={2019},
  volume={},
  number={},
  pages={859-864},
  doi={10.1109/ICMLA.2019.00149}}

@online{usercounts,
  author = { Stuart Dredge},
  title = {How many users do Spotify, Apple Music and other streaming services have?},
  year = {Year},
  howpublished ={\url{https://musically.com/2022/02/03/spotify-apple-how-many-users-big-music-streaming-services/}},
  note = {Accessed: 2022-02-03}j
}

@inproceedings{xgboost,
author = {Chen, Tianqi and Guestrin, Carlos},
title = {XGBoost: A Scalable Tree Boosting System},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939785},
doi = {10.1145/2939672.2939785},
abstract = {Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {785–794},
numpages = {10},
keywords = {large-scale machine learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@inproceedings{catboost,
author = {Prokhorenkova, Liudmila and Gusev, Gleb and Vorobev, Aleksandr and Dorogush, Anna Veronika and Gulin, Andrey},
title = {CatBoost: Unbiased Boosting with Categorical Features},
year = {2018},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {This paper presents the key algorithmic techniques behind CatBoost, a new gradient boosting toolkit. Their combination leads to CatBoost outperforming other publicly available boosting implementations in terms of quality on a variety of datasets. Two critical algorithmic advances introduced in CatBoost are the implementation of ordered boosting, a permutation-driven alternative to the classic algorithm, and an innovative algorithm for processing categorical features. Both techniques were created to fight a prediction shift caused by a special kind of target leakage present in all currently existing implementations of gradient boosting algorithms. In this paper, we provide a detailed analysis of this problem and demonstrate that proposed algorithms solve it effectively, leading to excellent empirical results.},
booktitle = {Proceedings of the 32nd International Conference on Neural Information Processing Systems},
pages = {6639–6649},
numpages = {11},
location = {Montr\'{e}al, Canada},
series = {NIPS'18}
}

@online{lloudness,
  author = { Aden Russell},
  title = {LUFS: How To Measure Your Track’s Loudness in Mastering},
  year = {2023},
  howpublished = {\url{https://www.edmprod.com/lufs/#:~:text=The%20measurement%20for%20LUFS%20is,9%20LUFS}},
  note = {Accessed: 2023-07-31},
}

@article{CNN,
  title={Hit Song Prediction for Pop Music by Siamese CNN with Ranking Loss},
  author={Lang-Chi Yu and Yi-Hsuan Yang and Yun-Ning Hung and Yian Chen},
  journal={ArXiv},
  year={2017},
  volume={abs/1710.10814},
  url={https://api.semanticscholar.org/CorpusID:8608506}
}

@article{rfchoice,
title = {A comparison of random forest variable selection methods for classification prediction modeling},
journal = {Expert Systems with Applications},
volume = {134},
pages = {93-101},
year = {2019},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.05.028},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419303574},
author = {Jaime Lynn Speiser and Michael E. Miller and Janet Tooze and Edward Ip},
keywords = {Random forest, Variable selection, Feature reduction, Classification},
abstract = {Random forest classification is a popular machine learning method for developing prediction models in many research settings. Often in prediction modeling, a goal is to reduce the number of variables needed to obtain a prediction in order to reduce the burden of data collection and improve efficiency. Several variable selection methods exist for the setting of random forest classification; however, there is a paucity of literature to guide users as to which method may be preferable for different types of datasets. Using 311 classification datasets freely available online, we evaluate the prediction error rates, number of variables, computation times and area under the receiver operating curve for many random forest variable selection methods. We compare random forest variable selection methods for different types of datasets (datasets with binary outcomes, datasets with many predictors, and datasets with imbalanced outcomes) and for different types of methods (standard random forest versus conditional random forest methods and test based versus performance based methods). Based on our study, the best variable selection methods for most datasets are Jiang's method and the method implemented in the VSURF R package. For datasets with many predictors, the methods implemented in the R packages varSelRF and Boruta are preferable due to computational efficiency. A significant contribution of this study is the ability to assess different variable selection techniques in the setting of random forest classification in order to identify preferable methods based on applications in expert and intelligent systems.}
}

@ARTICLE{unbalanced,
  author={Wang, Le and Han, Meng and Li, Xiaojuan and Zhang, Ni and Cheng, Haodong},
  journal={IEEE Access}, 
  title={Review of Classification Methods on Unbalanced Data Sets}, 
  year={2021},
  volume={9},
  number={},
  pages={64606-64628},
  doi={10.1109/ACCESS.2021.3074243}}

@article{hyper,
author = {Bischl, Bernd and Binder, Martin and Lang, Michel and Pielok, Tobias and Richter, Jakob and Coors, Stefan and Thomas, Janek and Ullmann, Theresa and Becker, Marc and Boulesteix, Anne-Laure and Deng, Difan and Lindauer, Marius},
title = {Hyperparameter optimization: Foundations, algorithms, best practices, and open challenges},
journal = {WIREs Data Mining and Knowledge Discovery},
volume = {13},
number = {2},
pages = {e1484},
keywords = {automl, hyperparameter optimization, machine learning, model selection, tuning},
doi = {https://doi.org/10.1002/widm.1484},
url = {https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.1484},
eprint = {https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/widm.1484},
abstract = {Abstract Most machine learning algorithms are configured by a set of hyperparameters whose values must be carefully chosen and which often considerably impact performance. To avoid a time-consuming and irreproducible manual process of trial-and-error to find well-performing hyperparameter configurations, various automatic hyperparameter optimization (HPO) methods—for example, based on resampling error estimation for supervised machine learning—can be employed. After introducing HPO from a general perspective, this paper reviews important HPO methods, from simple techniques such as grid or random search to more advanced methods like evolution strategies, Bayesian optimization, Hyperband, and racing. This work gives practical recommendations regarding important choices to be made when conducting HPO, including the HPO algorithms themselves, performance evaluation, how to combine HPO with machine learning pipelines, runtime improvements, and parallelization. This article is categorized under: Algorithmic Development > Statistics Technologies > Machine Learning Technologies > Prediction},
year = {2023}
}


@ARTICLE{8327835,
  author={Lee, Junghyuk and Lee, Jong-Seok},
  journal={IEEE Transactions on Multimedia}, 
  title={Music Popularity: Metrics, Characteristics, and Audio-Based Prediction}, 
  year={2018},
  volume={20},
  number={11},
  pages={3173-3182},
  doi={10.1109/TMM.2018.2820903}}

@BOOK{hyperbook,
  TITLE = {Hyperparameter Tuning with Python},
  SUBTITLE = {Boost your machine learning model's performance via hyperparameter tuning},
  AUTHOR = {Louis Owen},
  YEAR = {2022},
  PUBLISHER = {Packt Publishing Ltd},
}

@inproceedings{shulman2016predictability,
  title={Predictability of popularity: Gaps between prediction and understanding},
  author={Shulman, Benjamin and Sharma, Amit and Cosley, Dan},
  booktitle={Proceedings of the international AAAI conference on web and social media},
  volume={10},
  number={1},
  pages={348--357},
  year={2016}
}

@article{881888,
    author = {Dorien Herremans, David Martens and Kenneth Sörensen},
    title = {Dance Hit Song Prediction},
    journal = {Journal of New Music Research},
    volume = {43},
    number = {3},
    pages = {291-302},
    year = {2014},
    publisher = {Routledge},
    doi = {10.1080/09298215.2014.881888}
}

@article{Interiano2018MusicalTA,
  title={Musical trends and predictability of success in contemporary songs in and out of the top charts},
  author={Myra Interiano and Kamyar Kazemi and Lijia Wang and Jienian Yang and Zhaoxia Yu and Natalia L. Komarova},
  journal={Royal Society Open Science},
  year={2018},
  volume={5},
  url={https://api.semanticscholar.org/CorpusID:47020010}
}

@inproceedings{appxgboost,
author = {Murauer, Benjamin and Specht, G\"{u}nther},
title = {Detecting Music Genre Using Extreme Gradient Boosting},
year = {2018},
isbn = {9781450356404},
publisher = {International World Wide Web Conferences Steering Committee},
address = {Republic and Canton of Geneva, CHE},
url = {https://doi.org/10.1145/3184558.3191822},
doi = {10.1145/3184558.3191822},
abstract = {This paper summarizes our contribution to the CrowdAI music genre classification challenge "Learning to Recognise Musical Genre from Audio on the Web'' as part of the WebConference 2018. We utilize different approaches from the field of music analysis to predict the music genre of given mp3 music files, including a convolutional neural network for spectrogram classification, deep neural networks and ensemble methods using various numerical audio features. Our best results were obtained by an extreme gradient boosting classifier.},
booktitle = {Companion Proceedings of the The Web Conference 2018},
pages = {1923–1927},
numpages = {5},
keywords = {gradient boosting, music classification, neural network},
location = {Lyon, France},
series = {WWW '18}
}

@article{rf,
author = {Breiman, Leo},
title = {Random Forests},
year = {2001},
issue_date = {October 1 2001},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {45},
number = {1},
issn = {0885-6125},
url = {https://doi.org/10.1023/A:1010933404324},
doi = {10.1023/A:1010933404324},
abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
journal = {Mach. Learn.},
month = {oct},
pages = {5–32},
numpages = {28},
keywords = {regression, classification, ensemble}
}